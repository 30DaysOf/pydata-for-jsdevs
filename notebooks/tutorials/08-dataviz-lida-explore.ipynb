{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Project LIDA\n",
    "\n",
    "LIDA is a library for generating data visualizations and data-faithful infographics. LIDA is grammar agnostic (will work with any programming language and visualization libraries e.g. matplotlib, seaborn, altair, d3 etc) and works with multiple large language model providers (OpenAI, Azure OpenAI, PaLM, Cohere, Huggingface).Details on the components of LIDA are described in [this paper](https://arxiv.org/abs/2303.02927) - star [this project](https://aka.ms/lida/github) for updates. \n",
    "\n",
    "LIDA _treats visualizations as code_ and provides a clean api for generating, executing, editing, explaining, evaluating and repairing visualization code. Here are some tasks you can execute with LIDA.\n",
    "\n",
    "- ✅ Data Summarization\n",
    "- ✅ Goal Generation\n",
    "- ✅ Visualization Generation\n",
    "- ✅ Visualization Editing\n",
    "- ✅ Visualization Explanation\n",
    "- ✅ Visualization Evaluation and Repair\n",
    "- ✅ Visualization Recommendation\n",
    "- ✅ Infographic Generation (beta) # pip install lida[infographics]\n",
    "\n",
    "![LIDA Modules illustrated](https://github.com/microsoft/lida/raw/main/docs/images/lidamodules.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Summarization\n",
    "Given a dataset, generate a compact summary of that data in a compact natural language representation that serves as context for subsequent tasks. The goal of the summarizer is to _produce an dense-but-compact information summary for a given dataset that is useful as grounding context for visualization tasks_. The grounding context is defined as one that contains information an analyst would need to understand the dataset and the tasks that can be performed on it.\n",
    "\n",
    "See [paper](https://arxiv.org/pdf/2303.02927.pdf) for details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "from lida import Manager, TextGenerationConfig , llm  \n",
    "\n",
    "csvfile = \"./../../data/kaggle/IPL-2022.csv\"\n",
    "lida = Manager(text_gen = llm(\"openai\")) # palm, cohere .\n",
    "textgen_config = TextGenerationConfig(n=1, temperature=0.5, model=\"gpt-3.5-turbo-0301\", use_cache=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize\n",
    "summary = lida.summarize(csvfile)\n",
    "summary_data = list(summary.keys())\n",
    "for keys in summary_data:\n",
    "    print(keys, \":\", summary[keys])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Goal Generation\n",
    "\n",
    "Given the dataset \"context\" generated by the summarizer, the LLM must now _generate a question (hypothesis), a visualization (that addresses the question) and a rationale (for that visualization)_. The research found that requiring the LLM to produce a rationale led to more semantically meaningful goals.\n",
    "\n",
    "The generation API takes these parameters - the summary, the number of goals to generate (n) and a persona (optional) that influences the tone or context for the goals generated. And the textgen_config that configures parameters for the given model.\n",
    "\n",
    "See [paper](https://arxiv.org/pdf/2303.02927.pdf) for details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate 5 goals from the summary - with the persona is a fan of the Mumbai team\n",
    "goals = lida.goals(summary, n=5, textgen_config=textgen_config, persona=\"fam of the Mumbai team who wants to see their stats\") # exploratory data analysis\n",
    "\n",
    "# create a list of dictionaries containing the goal information\n",
    "import pandas as pd\n",
    "goal_list = []\n",
    "for goal in goals:\n",
    "    display(goal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# generate 10 goals from the summary with default persona\n",
    "goals = lida.goals(summary, n=10, textgen_config=textgen_config,) # exploratory data analysis\n",
    "\n",
    "# create a list of dictionaries containing the goal information\n",
    "import pandas as pd\n",
    "goal_list = []\n",
    "for goal in goals:\n",
    "    goal_dict = {'Question': goal.question, 'Visualization': goal.visualization, 'Rationale': goal.rationale}\n",
    "    goal_list.append(goal_dict)\n",
    "df = pd.DataFrame(goal_list)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize A Goal \n",
    "charts = lida.visualize(summary=summary, goal=goals[0]) # exploratory data analysis\n",
    "print(\"Charts length:\", len(charts))\n",
    "charts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize a Goal - and specify a library\n",
    "target = goals[2]\n",
    "library = \"matplotlib\"\n",
    "charts = lida.visualize(summary=summary, goal=target, library=library) # exploratory data analysis\n",
    "charts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize it again - and specify a different library and textgen_config (change temperature)\n",
    "target = goals[2]\n",
    "library = \"seaborn\"\n",
    "textgen_config = TextGenerationConfig(n=1, temperature=0.2, use_cache=True)\n",
    "charts = lida.visualize(summary=summary, goal=target,library=library,textgen_config=textgen_config) # exploratory data analysis\n",
    "charts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_query = \"What is the frequency of toss decisions based on team ?\"\n",
    "textgen_config = TextGenerationConfig(n=1, temperature=0.2, use_cache=True)\n",
    "charts = lida.visualize(summary=summary, goal=user_query, textgen_config=textgen_config)  \n",
    "charts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edit visuaization - modify using natural language\n",
    "instructions = [\"change the color to green\", \"translate the title to french\"]\n",
    "edited_charts = lida.edit(code=charts[0],  summary=summary, instructions=instructions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Caching\n",
    "Each manager method takes a `textgen_config` argument which is a dictionary that can be used to configure the text generation process (with parameters for model, temperature, max_tokens, topk etc). One of the keys in this dictionary is `use_cache`. If set to `True`, the manager will cache the generated text associated with that method. Use for speedup and to avoid hitting API limits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install lida \n",
    "# !pip install lida[infographics] # for infographics support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lida import Manager, TextGenerationConfig , llm  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Summarize Data, Generate Goals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lida = Manager(text_gen = llm(\"openai\", api_key=None)) # !! api key\n",
    "textgen_config = TextGenerationConfig(n=1, temperature=0.5, model=\"gpt-3.5-turbo-0301\", use_cache=True)\n",
    "#csvfile = \"https://raw.githubusercontent.com/uwdata/draco/master/data/cars.csv\"\n",
    "csvfile = \"./../../data/kaggle/IPL-2022.csv\"\n",
    "summary = lida.summarize(csvfile, summary_method=\"default\", textgen_config=textgen_config)  \n",
    "goals = lida.goals(summary, n=5, textgen_config=textgen_config)\n",
    "\n",
    "for goal in goals:\n",
    "    display(goal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# goals can also be based on a persona \n",
    "# persona = \"a mechanic who wants to buy a car that is cheap but has good gas mileage\"\n",
    "persona = \"a enthusiastic sports fan who likes to use a casual tone and loves to know all the key stats of the game\"\n",
    "personal_goals = lida.goals(summary, n=5, persona=persona, textgen_config=textgen_config)\n",
    "for goal in personal_goals:\n",
    "    display(goal)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Generate Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are 5 goals above\n",
    "# Visualizations worked for i=0, 2, 3\n",
    "i = 0\n",
    "print(goals[i])\n",
    "\n",
    "library = \"seaborn\"\n",
    "textgen_config = TextGenerationConfig(n=1, temperature=0.2, use_cache=True)\n",
    "charts = lida.visualize(summary=summary, goal=goals[i], textgen_config=textgen_config, library=library)  \n",
    "charts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are 5 goals above\n",
    "# Visualizations worked for i=0, 2, 3\n",
    "i = 2\n",
    "print(goals[i])\n",
    "\n",
    "library = \"seaborn\"\n",
    "textgen_config = TextGenerationConfig(n=1, temperature=0.2, use_cache=True)\n",
    "charts = lida.visualize(summary=summary, goal=goals[i], textgen_config=textgen_config, library=library)  \n",
    "charts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are 5 goals above\n",
    "# Visualizations worked for i=0, 2, 3\n",
    "i = 3\n",
    "print(goals[i])\n",
    "\n",
    "library = \"seaborn\"\n",
    "textgen_config = TextGenerationConfig(n=1, temperature=0.2, use_cache=True)\n",
    "charts = lida.visualize(summary=summary, goal=goals[i], textgen_config=textgen_config, library=library)  \n",
    "charts[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Generate visualization via a \"user query\"   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#user_query = \"What is the average price of cars by type?\"\n",
    "user_query = \"What is the average runs scored by a team in a given stadium?\"\n",
    "textgen_config = TextGenerationConfig(n=1, temperature=0.2, use_cache=True)\n",
    "charts = lida.visualize(summary=summary, goal=user_query, textgen_config=textgen_config)  \n",
    "charts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_query = \"Who won the most cricket games?\"\n",
    "textgen_config = TextGenerationConfig(n=1, temperature=0.2, use_cache=True)\n",
    "charts = lida.visualize(summary=summary, goal=user_query, textgen_config=textgen_config)  \n",
    "charts[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. VizOps\n",
    "\n",
    "Given that LIDA represents visualizations as code,\n",
    "the VISGENERATOR also implements submodules\n",
    "to perform operations on this representation. \n",
    "\n",
    "This includes \n",
    "- **Natural language based visualization refinement**: Provides a conversational api to iteratively\n",
    "4Execution in a sandbox environment is recommended.\n",
    "refine generated code (e.g., translate chart t hindi\n",
    ". . . zoom in by 50% etc) which can then be executed to generate new visualizations.\n",
    "- **Visualization explanations and accessibility**:\n",
    "Generates natural language explanations (valuable\n",
    "for debugging and sensemaking) as well as accessibility descriptions (valuable for supporting users\n",
    "with visual impairments).\n",
    "\n",
    "- **Visualization code self-evaluation and repair**:\n",
    "Applies an LLM to self-evaluate generated code on\n",
    "multiple dimensions (see section 4.1.2).\n",
    "\n",
    "- **Visualization recommendation**: Given some context (goals, or an existing visualization), recommend additional visualizations to the user (e.g., for\n",
    "comparison, or to provide additional perspectives).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1 Natural language based visualization refinement \n",
    "\n",
    "Given some code, modify it based on natural language instructions. This yields a new code snippet that can be executed to generate a new visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "code = charts[0].code\n",
    "textgen_config = TextGenerationConfig(n=1, temperature=0, use_cache=True)\n",
    "instructions = [\"make the chart height and width equal\", \"change the color of the chart to red\", \"translate the chart to spanish\"]\n",
    "edited_charts = lida.edit(code=code,  summary=summary, instructions=instructions, library=library, textgen_config=textgen_config)\n",
    "edited_charts[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 Visualization explanations and accessibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explanations = lida.explain(code=code, library=library, textgen_config=textgen_config) \n",
    "for row in explanations[0]:\n",
    "    print(row[\"section\"],\" ** \", row[\"explanation\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3 Visualization code self-evaluation and repair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluations = lida.evaluate(code=code,  goal=goals[i], textgen_config=textgen_config, library=library)[0] \n",
    "for eval in evaluations:\n",
    "    print(eval[\"dimension\"], \"Score\" ,eval[\"score\"], \"/ 10\")\n",
    "    print(\"\\t\", eval[\"rationale\"][:200])\n",
    "    print(\"\\t**********************************\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization Recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "textgen_config = TextGenerationConfig(n=2, temperature=0.2, use_cache=True)\n",
    "recommended_charts =  lida.recommend(code=code, summary=summary, n=2,  textgen_config=textgen_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Recommended {len(recommended_charts)} charts\")\n",
    "for chart in recommended_charts:\n",
    "    display(chart) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Infographics (Beta)\n",
    "\n",
    "- Explores using LIDA to generate infographics from an existing visualization \n",
    "- Uses the `peacasso` package, and loads open source stable diffusion models \n",
    "- You will need to run `pip install lida[infographics]` to install the required dependencies.\n",
    "- Currently work in progress (work being done to post process infographics with chart axis and title overlays from the original visualization, add presets for different infographic styles, and add more stable diffusion models)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install lida[infographics] \n",
    "# ensure you have a GPU runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🚨 | Uncomment below to try it out only if you have access to \n",
    "#      a GPU Runtime in your GitHub Codespaces or Docker Desktop\n",
    "\n",
    "# infographics = lida.infographics(visualization = edited_charts[0].raster, n=1, style_prompt=\"pastel art, green pearly rain drops, highly detailed, no blur, white background\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🚨 | Uncomment below to try it out only if you have access to \n",
    "#      a GPU Runtime in your GitHub Codespaces or Docker Desktop\n",
    "#      and successfully ran the previous cell\n",
    "from lida.utils import plot_raster\n",
    "# plot_raster([edited_charts[0].raster, infographics[\"images\"][0]]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "189101fc34b85ec7417252a331b6b3ef556b71030ac1f6fe00bfbe1409305460"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
